{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost: Finetuning, regularization and debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Define AdaBoost pipeline & GridSearch\u001b[39;00m\n\u001b[32m     37\u001b[39m base_estimator = DecisionTreeClassifier(max_depth=\u001b[32m1\u001b[39m)\n\u001b[32m     39\u001b[39m pipe = Pipeline([\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     (\u001b[33m\"\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mAdaBoostClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     41\u001b[39m ])\n\u001b[32m     43\u001b[39m param_grid = {\n\u001b[32m     44\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclf__n_estimators\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m50\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m150\u001b[39m],\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mclf__learning_rate\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[32m0.5\u001b[39m, \u001b[32m1.0\u001b[39m, \u001b[32m1.5\u001b[39m]\n\u001b[32m     46\u001b[39m }\n\u001b[32m     48\u001b[39m grid = GridSearchCV(pipe, param_grid, scoring=\u001b[33m\"\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m\"\u001b[39m, cv=cv, n_jobs=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "# === AdaBoost Tuning ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib, os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Load preprocessed data and pipeline\n",
    "df = pd.read_csv(\"../data/cox-violent-preprocessed.csv\")\n",
    "pipeline = joblib.load(\"../models/pipeline_preprocessing.pkl\")\n",
    "\n",
    "# Feature preparation\n",
    "X_raw = df.drop(\"is_recid\", axis=1)\n",
    "y = df[\"is_recid\"]\n",
    "X_transformed = pipeline.transform(X_raw)\n",
    "selected_features = [\"age\", \"sex\", \"juv_misd_count\", \"juv_fel_count\", \"priors_count\", \"c_charge_degree\", \"c_charge_desc\"]\n",
    "feature_indices = [X_raw.columns.get_loc(f) for f in selected_features]\n",
    "X_selected = X_transformed[:, feature_indices]\n",
    "\n",
    "# Data split\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_selected, y, test_size=0.15, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.176, stratify=y_trainval, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define AdaBoost pipeline & GridSearch\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"clf\", AdaBoostClassifier(base_estimator=base_estimator, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"clf__n_estimators\": [50, 100, 150],\n",
    "    \"clf__learning_rate\": [0.5, 1.0, 1.5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring=\"roc_auc\", cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "y_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "y_pred = best_model.predict(X_val)\n",
    "print(\"Validation Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_pred):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_pred):.3f}\")\n",
    "print(f\"F1: {f1_score(y_val, y_pred):.3f}\")\n",
    "print(f\"AUC: {roc_auc_score(y_val, y_proba):.3f}\")\n",
    "\n",
    "# Learning curve\n",
    "train_sizes, train_scores, val_scores = learning_curve(best_model, X_train, y_train, cv=cv, scoring=\"f1\", train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label=\"Train F1\")\n",
    "plt.plot(train_sizes, val_scores.mean(axis=1), label=\"Validation F1\")\n",
    "plt.title(\"Learning Curve - AdaBoost\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"../reports/02_modeling/tuning\", exist_ok=True)\n",
    "plt.savefig(\"../reports/02_modeling/tuning/learning_curve_adaboost_finetuned.png\")\n",
    "plt.show()\n",
    "\n",
    "# === Logging dynamic results to CSV ===\n",
    "\n",
    "model_name = \"AdaBoost\"\n",
    "\n",
    "# Prepare log path\n",
    "log_file = Path(\"../reports/02_modeling/tuning/model_validation_comparison_log.csv\")\n",
    "log_file.parent.mkdir(parents=True, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "# Prepare result row dynamically\n",
    "result_row = {\n",
    "    \"Model\": model_name,\n",
    "    \"Accuracy\": round(accuracy_score(y_val, y_pred), 3),\n",
    "    \"Precision\": round(precision_score(y_val, y_pred), 3),\n",
    "    \"Recall\": round(recall_score(y_val, y_pred), 3),\n",
    "    \"F1 Score\": round(f1_score(y_val, y_pred), 3),\n",
    "    \"AUC\": round(roc_auc_score(y_val, y_proba), 3),\n",
    "    \"Best Params\": str(grid.best_params_)\n",
    "}\n",
    "\n",
    "# Append to log file\n",
    "if log_file.exists():\n",
    "    df_log = pd.read_csv(log_file)\n",
    "else:\n",
    "    df_log = pd.DataFrame(columns=result_row.keys())\n",
    "\n",
    "df_log = pd.concat([df_log, pd.DataFrame([result_row])], ignore_index=True)\n",
    "df_log.to_csv(log_file, index=False)\n",
    "df_log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
